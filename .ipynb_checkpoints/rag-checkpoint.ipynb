{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06d99aa",
   "metadata": {},
   "source": [
    "# Create and run a local RAG pipeline from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ea7bfc-b5c8-401f-9742-e247fc60f021",
   "metadata": {},
   "source": [
    "## What is RAG?\n",
    "\n",
    "RAG stands for Retrieval Augmenta Generation.\n",
    "The goal of RAG is to take information and pass it to an LLM and generate answers based on that information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0c04a3-9dfa-4fb8-897a-61c62e82796e",
   "metadata": {},
   "source": [
    "## Steps to building the RAG system from scratch\n",
    "\n",
    "1. Open a PDF document (or a group of PDF documents)\n",
    "2. Format the text of the document/(s) suitably to feed into an embedding model.\n",
    "3. Embed all of the chunks of text in the document/(s) and turn them into numerical representations which can be stored for later.\n",
    "4. Build a retrieval system that uses vector search to find the relevant chunk of text based on the query.\n",
    "5. Create a prompt that incorporates the retrieved pieces of text.\n",
    "6. Generate an answer to the quesry based on the passages of the textbook with an LLM.\n",
    "\n",
    "All will be done locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a87eaf-b3f7-4e5a-be95-a96c07a6b160",
   "metadata": {},
   "source": [
    "## 1. Document processing and embedding creation.\n",
    "\n",
    "Steps:\n",
    "1. Import the PDF document/(s)\n",
    "2. Process text for embedding (e.g. split into chunks of sentences)\n",
    "3. Embed text chunks with embedding model\n",
    "4. Save embeddings for later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3991678-24c0-4745-84f7-0c531be3b046",
   "metadata": {},
   "source": [
    "### Import the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a600ec4d-7f7b-4061-aecd-2af3f17e6868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Get PDF document path\n",
    "pdf_path = \"./Reference Documents/AI Engineering.pdf\"\n",
    "\n",
    "# Download PDF\n",
    "if os.path.exists(pdf_path):\n",
    "    print(\"[INFO] File exists\")\n",
    "else:\n",
    "    print(\"[INFO] File does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69886a9-c865-4ba5-a8c2-fa3ca63811d7",
   "metadata": {},
   "source": [
    "### Opening the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf45c85-ebe0-48b3-9019-898271dadaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # used to open pdfs\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text:str) -> str:\n",
    "    # Performing minor formatting on text\n",
    "    cleaned_text = text.replace(\"\\n\",\" \").strip()\n",
    "    \n",
    "    return cleaned_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
